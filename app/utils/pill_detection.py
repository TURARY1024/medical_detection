
# import easyocr
import base64

from rembg import remove
import argparse
import cv2
import numpy as np


# åˆå§‹åŒ– OpenOCR å¼•æ“
from openocr import OpenOCR
import logging

from app.utils.image_io import read_image_safely

logging.getLogger("openrec").setLevel(logging.ERROR)
ocr_engine = OpenOCR(backend='onnx', device='cpu')
# ocr_engine = OpenOCR(backend="onnx", det_model_path="models/openocr_det_model.onnx", rec_model_path="models/openocr_rec_model.onnx")


from app.utils.matcher import lcs_score, match_ocr_to_front_back_by_permuted_ocr
from app.utils.ocr_utils import recognize_with_openocr
from app.utils.shape_color_utils import (
    rotate_image_by_angle,
    enhance_contrast,
    desaturate_image,
    enhance_for_blur,
    extract_dominant_colors_by_ratio,
    detect_shape_from_image
)

# Import YOLO
import ultralytics
# å¥—ç”¨å­—é«”ï¼ˆç”¨ FontPropertiesï¼‰
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
from sklearn.cluster import KMeans

zh_font = FontProperties(fname="/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc")

import itertools
import pandas as pd
from pathlib import Path
from pillow_heif import register_heif_opener

register_heif_opener()
from collections import defaultdict
from inference_sdk import InferenceHTTPClient
from PIL import Image
from pathlib import Path
import cv2
# import pyheif
import numpy as np
import json, re
from rembg import remove

# from google.colab.patches import cv2_imshow
# === åˆå§‹åŒ– ===
###
# CLIENT = InferenceHTTPClient(
#    api_url="https://serverless.roboflow.com",
#    api_key="kylIYUWNLWHPy2RXUVOe"
# )
# MODEL_ID = "ai-drug-analysis-service/3"
###
# create an inference client
# å¥—ç”¨å­—é«”ï¼ˆç”¨ FontPropertiesï¼‰

from matplotlib.font_manager import FontProperties


zh_font = FontProperties(fname="/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc")


from pillow_heif import register_heif_opener

register_heif_opener()

from inference_sdk import InferenceHTTPClient

import cv2

from rembg import remove
from ultralytics import YOLO
det_model = YOLO("/path/to/best.pt")

CLIENT = InferenceHTTPClient(
    api_url="https://detect.roboflow.com",
    api_key="SOlzinVqG2xuWsPUUGRp"
    # api_key="kylIYUWNLWHPy2RXUVOe"
)
MODEL_ID = "pill-detection-poc-i0b3g/1"


####

def generate_image_versions(base_img):
    v1 = enhance_contrast(base_img, 1.5, 1.5, -0.5)
    v2 = desaturate_image(v1)
    v3 = enhance_contrast(base_img, 5.5, 2.0, -1.0)
    v4 = desaturate_image(v3)
    v5 = enhance_for_blur(base_img)
    return [
        (base_img, "åŸåœ–"),
        (v1, "å¢å¼·1"),
        (v2, "å»é£½å’Œ1"),
        (v3, "å¢å¼·2"),
        (v4, "å»é£½å’Œ2"),
        (v5, "æ¨¡ç³Šå„ªåŒ–")
    ]


def get_best_ocr_texts(image_versions, angles=[0, 45, 90, 135, 180, 225, 270, 315], ocr_engine=None):
    version_results = {}
    score_dict = {}
    for img_v, version_name in image_versions:
        for angle in angles:
            rotated = rotate_image_by_angle(img_v, angle)
            full_name = f"{version_name}_æ—‹è½‰{angle}"
            texts, score = recognize_with_openocr(rotated, ocr_engine=ocr_engine, name=full_name, min_score=0.8)

            # print(f"ğŸ” {full_name} => {texts} (score={score:.3f})")#è¨»è§£SSS
            version_results[full_name] = texts
            score_dict[full_name] = score

    score_combined = {
        k: sum(len(txt) for txt in version_results[k]) * score_dict[k]
        for k in version_results
    }
    best_name = max(score_combined, key=score_combined.get)
    return version_results[best_name], best_name, score_dict[best_name]


def get_bbox_from_rembg_alpha(img_path):
    input_img = cv2.imread(img_path)
    rembg_img = remove(input_img)

    if rembg_img.shape[2] == 4:
        alpha = rembg_img[:, :, 3]
        alpha = cv2.GaussianBlur(alpha, (5, 5), 0)
        _, mask = cv2.threshold(alpha, 50, 255, cv2.THRESH_BINARY)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))
            return rembg_img, (x, y, w, h)  # âœ return cropped image & bounding box
    return None, None


# === æ¨¡çµ„åŒ–ï¼šå¾å®Œæ•´åœ–ç‰‡èˆ‡åµæ¸¬æ¡†ä¸­æ“·å–è—¥ç‰©å€åŸŸ ===
# def extract_pill_region(img_path, detection_result, margin=10):
def extract_pill_region(input_img, detection_result, margin=10):
    #    input_img = read_image_safely(img_path)
    if input_img is None:
        # print(f"âŒ extract_pill_region: ç„¡æ³•è®€å–åœ–ç‰‡ï¼š{img_path}")#è¨»è§£SSS
        return None, None

    try:
        h_img, w_img = input_img.shape[:2]
        cx, cy = detection_result["x"], detection_result["y"]
        bw, bh = detection_result["width"], detection_result["height"]

        x0 = max(0, int(cx - bw / 2) - margin)
        y0 = max(0, int(cy - bh / 2) - margin)
        x1 = min(w_img, int(cx + bw / 2) + margin)
        y1 = min(h_img, int(cy + bh / 2) + margin)

        cropped_original = input_img[y0:y1, x0:x1]

        try:
            cropped_removed = remove(cropped_original)
        except Exception as e:
            # print(f"âŒ rembg å»èƒŒå¤±æ•—ï¼š{e}")#è¨»è§£SSS
            return cropped_original, None

        return cropped_original, cropped_removed

    except Exception as e:
        # print(f"â— extract_pill_region éŒ¯èª¤ï¼š{e}")#è¨»è§£SSS
        return None, None


# def fallback_rembg_bounding(img_path):
# input_img = read_image_safely(img_path)
def fallback_rembg_bounding(input_img):
    if input_img is None:
        # print(f"âŒ fallback: ç„¡æ³•è®€å–åœ–ç‰‡ï¼š{img_path}")#è¨»è§£SSS
        return None, None

    try:
        rembg_img = remove(input_img)
    except Exception as e:
        print(f"âŒ rembg å»èƒŒå¤±æ•—ï¼š{e}")
        return None, None

    if rembg_img is None or rembg_img.shape[2] < 4:
        print(f"âš ï¸ rembg å›å‚³çµæœç•°å¸¸")
        return None, None

    try:
        alpha = rembg_img[:, :, 3]
        alpha = cv2.GaussianBlur(alpha, (5, 5), 0)
        _, mask = cv2.threshold(alpha, 50, 255, cv2.THRESH_BINARY)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))
            cropped = rembg_img[y:y + h, x:x + w]
            return input_img[y:y + h, x:x + w], cropped  # è¿”å›åŸåœ–å€å¡Šã€å»èƒŒå€å¡Š
        else:
            print("âš ï¸ fallback æ²’æœ‰åµæ¸¬åˆ°è¼ªå»“")
    except Exception as e:
        print(f"â— fallback rembg bounding å‡ºéŒ¯ï¼š{e}")

    return None, None


def test_batch_all_images(ROOT_FOLDER: Path, excel_path: str, start_index=1, end_index=403):
    roboflow_success = 0
    roboflow_total = 0

    shape_total = 0
    shape_success = 0

    total_images = 0
    text_success_total = 0
    shape_success_total = 0

    total_success = 0
    per_drug_stats = defaultdict(lambda: {"total": 0, "success": 0})
    fail_logs = []

    # === è—¥ç‰©åœ–ç‰‡æ ¹è³‡æ–™å¤¾ ===
    # ROOT_FOLDER = Path("/content/drive/MyDrive/ç•¢æ¥­å°ˆé¡Œ/drug_photo_copy")

    # === è®€å– Excel è³‡æ–™ ===
    # excel_path = "/content/drive/MyDrive/TEST_DRUG/TESTData.xlsx"
    df = pd.read_excel(excel_path)

    # === è¨­å®šä½ æƒ³æ¸¬è©¦çš„èµ·å§‹èˆ‡çµæŸã€Œç”¨é‡æ’åºã€ç¯„åœ ===
    start_index = 1
    end_index = 403

    # === éæ¿¾è³‡æ–™è¡¨ç¯„åœ ===
    df_range = df[(df["ç”¨é‡æ’åº"] >= start_index) & (df["ç”¨é‡æ’åº"] <= end_index)]
    # === åˆå§‹åŒ– PRUNE åˆ†é¡å­—å…¸ ===
    shape_dict = {"åœ“å½¢": [], "é•·åœ“å½¢": [], "å…¶ä»–": []}
    text_dict = {"has_text": [], "none": []}

    for _, row in df_range.iterrows():
        usage_order = int(row.get("ç”¨é‡æ’åº", -1))

        # === å¤–å‹åˆ†é¡ ===
        shape = str(row.get("å½¢ç‹€", "")).strip()
        if shape == "åœ“å½¢":
            shape_dict["åœ“å½¢"].append(usage_order)
        elif shape == "é•·åœ“å½¢":
            shape_dict["é•·åœ“å½¢"].append(usage_order)
        else:
            shape_dict["å…¶ä»–"].append(usage_order)

        # === æ–‡å­—åˆ†é¡ ===
        text = str(row.get("æ–‡å­—", "")).replace(" ", "").upper()
        if text == "F:NONE|B:NONE":
            text_dict["none"].append(usage_order)
        else:
            text_dict["has_text"].append(usage_order)

    # === è¨˜éŒ„æ‰¾ä¸åˆ°çš„è³‡æ–™å¤¾ ===
    missing_entries = []

    # === é€ç­†è™•ç† ===
    for _, row in df_range.iterrows():
        raw_name = str(row["å­¸å"]).strip()
        drug_name = raw_name.replace("/", " ")
        folder_path = ROOT_FOLDER / drug_name

        if not folder_path.exists():
            # print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™å¤¾ï¼š{folder_path}")
            missing_entries.append({
                "ç”¨é‡æ’åº": row["ç”¨é‡æ’åº"],
                "å­¸å": raw_name
            })
            continue

        # print(f"\nğŸ“¦ é–‹å§‹è¾¨è­˜è—¥ç‰©ï¼š{drug_name}ï¼ˆä¾†æºï¼š{folder_path}ï¼‰")#è¨»è§£SSS

        # âœ… ä½ çš„è¾¨è­˜ç¨‹å¼ç¢¼è²¼åœ¨é€™è£¡ï¼ˆè¨˜å¾— BASE_DIR = folder_pathï¼‰
        BASE_DIR = folder_path
        exts = {".jpg", ".jpeg", ".png", ".heic", ".heif"}
        # âœ… éæ¿¾æ‰ NEW_PHOTOS è³‡æ–™å¤¾ + è®Šå½¢åœ–æª”å
        skip_keywords = ["_rot", "_bright", "_noise", "_flip", "_removed"]
        img_files = [
            p for p in BASE_DIR.rglob("*")
            if p.suffix.lower() in exts
               and "NEW_PHOTOS" not in p.parts
               and not any(keyword in p.name for keyword in skip_keywords)
        ]

        version_results = {}
        score_dict = {}

        # æ¯ 45 åº¦æ—‹è½‰ä¸€æ¬¡
        rotation_angles = [0, 45, 90, 135, 180, 225, 270, 315]

        # === ä¸»è™•ç†æµç¨‹ ===

        for img_path in img_files:
            total_images += 1
            # é æœŸæ–‡å­—èˆ‡æ˜¯å¦æ‡‰æœ‰æ–‡å­—
            # row æ˜¯ç›®å‰åœ–ç‰‡å°æ‡‰åˆ°çš„ rowï¼ˆé€™å¼µåœ–åŸå§‹çš„ï¼‰
            raw_row = row
            expected_text = str(raw_row.get("æ–‡å­—", "")).strip()
            expected_text_clean = expected_text.replace(" ", "").upper()
            has_expected_text = not (expected_text_clean == "F:NONE|B:NONE")

            try:
                # è®€å–åœ–ç‰‡ï¼ˆè‡ªå‹•åˆ¤æ–·æ˜¯å¦ç‚º HEICï¼‰
                input_img = read_image_safely(img_path)
                if input_img is None:
                    print(f"âš ï¸ ç„¡æ³•è®€å–åœ–ç‰‡ï¼š{img_path.name}ï¼Œè·³é")
                    continue

                # âœ… Roboflow æ¨ç†æ™‚æ”¹ç”¨ PIL.Image.fromarray è½‰æ›
                rgb_pil = Image.fromarray(cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB))
                result = CLIENT.infer(rgb_pil, model_id=MODEL_ID)
                preds = result.get("predictions", [])
                # â¤ åŠ å…¥çµ±è¨ˆ Roboflow æˆåŠŸç‡
                roboflow_total += 1
                if preds:
                    roboflow_success += 1
                    cropped_original, cropped_removed = extract_pill_region(img_path, preds[0])
                    # print("âœ… Roboflow åµæ¸¬æˆåŠŸ")#è¨»è§£SSS
                else:
                    # print("âš ï¸ Roboflow åµæ¸¬å¤±æ•—ï¼Œæ”¹ç”¨ rembg fallback")#è¨»è§£SSS
                    cropped_original, cropped_removed = fallback_rembg_bounding(img_path)
                    if cropped_original is None:
                        print("âŒ fallback ä¹Ÿå¤±æ•—ï¼Œè·³éæ­¤åœ–ç‰‡")
                        # cv2_imshow(input_img)
                        continue

                # ï¼ˆå¯é¸ï¼‰é¡¯ç¤ºå»èƒŒåœ–
                # cv2_imshow(cropped_removed)#è¨»è§£SSS
                # å½¢ç‹€è¾¨è­˜
                shape, result = detect_shape_from_image(cropped_removed, cropped_original, expected_shape=None,
                                                        debug=False)
                ##é¡è‰²è¾¨è­˜##
                colors = extract_dominant_colors_by_ratio(cropped_removed, visualize=False)

                # å…­å€‹åœ–ç‰‡å¢å¼·ç‰ˆæœ¬
                image_versions = generate_image_versions(cropped_removed)
                best_texts, best_name, best_score = get_best_ocr_texts(image_versions)

                is_blurry = (not best_texts) and (best_score < 0.6)

                # print(f"\nğŸŒŸ æœ€ä½³ç‰ˆæœ¬ï¼š{best_name}")
                # print(f"ğŸ“‹ åˆä½µè¾¨è­˜çµæœï¼š{best_texts}")
                # è‹¥å®Œå…¨ç„¡æ–‡å­—è¾¨è­˜ï¼Œå°±æ¨™è¨˜ç‚º NONE

                ocr_is_none = (not best_texts) or (best_score < 0.5)
                ocr_match_result = None  # åˆå§‹åŒ–çµæœè®Šæ•¸

                if ocr_is_none:
                    # ç„¡æ–‡å­—ï¼Œç›´æ¥ä½¿ç”¨å¤–å‹èˆ‡æ˜¯å¦ç„¡æ–‡å­—æ¢ä»¶ PRUNEï¼ˆä¸åŸ·è¡Œ OCR æ¯”å°ï¼‰
                    candidate_orders = list(set(text_dict["none"]) & set(shape_dict.get(shape, [])))
                    pruned_df = df_range[df_range["ç”¨é‡æ’åº"].isin(candidate_orders)] if candidate_orders else df_range
                    ocr_match_result = None  # ç„¡éœ€æ¯”å°

                else:
                    # â¤ æœ‰æ–‡å­—ï¼šå…ˆç›´æ¥æ¯”å°å…¨éƒ¨è³‡æ–™
                    ocr_match_result = match_ocr_to_front_back_by_permuted_ocr(best_texts, df_range)

                    # è‹¥åˆ†æ•¸åä½ï¼Œå‰‡ fallback é€²è¡Œ PRUNE
                    front_score = ocr_match_result.get("front", {}).get("score", 0) if ocr_match_result else 0
                    back_score = ocr_match_result.get("back", {}).get("score", 0) if ocr_match_result else 0
                    low_score = max(front_score, back_score) < 0.8

                    if low_score:
                        candidate_orders = shape_dict.get(shape, [])
                        pruned_df = df_range[
                            df_range["ç”¨é‡æ’åº"].isin(candidate_orders)] if candidate_orders else df_range
                        ocr_match_result = match_ocr_to_front_back_by_permuted_ocr(best_texts, pruned_df)

                is_correct = False  # é è¨­ç‚ºéŒ¯

                # â¤ æƒ…å¢ƒ 1ï¼šè³‡æ–™æœ¬ä¾†å°±æ²’æ–‡å­—ï¼Œä¸éœ€è¾¨è­˜
                if not has_expected_text:
                    # print("ğŸ“„ è³‡æ–™æ¨™è¨»ç‚ºç„¡æ–‡å­—ï¼Œç•¥éæ¯”å°")#è¨»è§£SSS
                    is_correct = True  # ç›´æ¥æ¨™è¨˜ç‚ºæˆåŠŸ
                elif ocr_match_result:
                    if "front" in ocr_match_result:
                        r = ocr_match_result["front"]
                        matched_row = r["row"]  # LCS å°åˆ°çš„è—¥å“
                        expected_name = raw_name.strip().upper()
                        matched_name = matched_row["å­¸å"].strip().upper()
                        is_correct = (expected_name == matched_name)

                        correctness = "ğŸ¯ æ­£ç¢ºè¾¨è­˜" if is_correct else f"âŒ éŒ¯èª¤è¾¨è­˜ï¼ˆé æœŸï¼š{expected_name}ï¼‰"

                        # print(f"âœ… æ­£é¢æ•´é«”æ¯”å°ï¼š{r['text']} â†’ {r['match']} (score={r['score']:.2f})") #è¨»è§£
                        # print(f"{correctness} | ğŸ” å­¸åï¼š{row['å­¸å']}ï¼Œç”¨é‡æ’åºï¼š{row['ç”¨é‡æ’åº']}")#è¨»è§£

                    if "back" in ocr_match_result:
                        r = ocr_match_result["back"]
                        matched_row = r["row"]  # LCS å°åˆ°çš„è—¥å“

                        expected_name = raw_name.strip().upper()
                        matched_name = matched_row["å­¸å"].strip().upper()
                        is_back_correct = (expected_name == matched_name)
                        if not is_correct:  # å¦‚æœæ­£é¢éŒ¯äº†ä½†èƒŒé¢å°ï¼Œä¾ç„¶è¦–ç‚ºæˆåŠŸ
                            is_correct = is_back_correct
                        correctness = "ğŸ¯ æ­£ç¢ºè¾¨è­˜" if is_back_correct else f"âŒ éŒ¯èª¤è¾¨è­˜ï¼ˆé æœŸï¼š{expected_name}ï¼‰"
                        # print(f"âœ… èƒŒé¢æ¯”å°ï¼š{r['text']} â†’ {r['match']} (score={r['score']:.2f})")#è¨»è§£
                        # print(f"{correctness} | ğŸ” å­¸åï¼š{row['å­¸å']}ï¼Œç”¨é‡æ’åºï¼š{row['ç”¨é‡æ’åº']}")#è¨»è§£
                else:
                    # print("âŒ ç„¡æ³•èˆ‡ä»»ä½•è—¥ç‰©ä»£ç¢¼åŒ¹é…")#è¨»è§£SSS
                    # â¤ é¡å¤–æ¢ä»¶ï¼šè‹¥ OCR ç„¡çµæœï¼Œä¸”æŸä¸€é¢å‰›å¥½æ˜¯ NONEï¼Œå‰‡è¦–ç‚ºæˆåŠŸ
                    if ocr_is_none and ("F:NONE" in expected_text or "B:NONE" in expected_text):
                        # print("âœ… OCR é›–ç„¡çµæœï¼Œä½†èˆ‡æ¨™è¨» NONE å°æ‡‰ï¼Œè¦–ç‚ºæˆåŠŸ")#è¨»è§£SSS
                        is_correct = True

                per_drug_stats[raw_name]["total"] += 1
                # âœ… ä¸ç®¡æœ‰æ²’æœ‰ expected textï¼Œåªè¦ is_correct å°±è¨˜æˆåŠŸ
                if is_correct:
                    total_success += 1
                    per_drug_stats[raw_name]["success"] += 1

                # âœ… çµ±è¨ˆç¸½æ•¸åƒ…åœ¨æœ‰æ¨™è¨»æ™‚è¨ˆå…¥ï¼ˆé¿å… NONE å° NONE å½±éŸ¿åŸºåº•ï¼‰
                if has_expected_text:

                    if not is_correct:
                        fail_logs.append({
                            "åœ–ç‰‡æª”å": img_path.name,
                            "åœ–ç‰‡è·¯å¾‘": str(img_path),
                            "è—¥å“å­¸å": raw_name,
                            "ç”¨é‡æ’åº": row["ç”¨é‡æ’åº"],
                            "æ­£ç¢ºæ–‡å­—": row.get("æ–‡å­—", ""),
                            "æ­£ç¢ºé¡è‰²": row.get("é¡è‰²", ""),
                            "OCRçµæœ_æ–‡å­—": best_texts if best_texts else "ç„¡æ–‡å­—",
                            "OCRçµæœ_é¡è‰²": colors
                        })

                # print(f"ğŸ“· åœ–ç‰‡ï¼š{img_path.name}")#è¨»è§£SSS
                # print(f"ğŸ”  OCR çµæœï¼š{best_texts}ï¼ˆæœ€ä½³ç‰ˆæœ¬ï¼š{best_name}ï¼Œä¿¡å¿ƒåˆ†æ•¸ï¼š{best_score:.3f}ï¼‰")#è¨»è§£SSS

                # print(f"ğŸ¨ è¾¨è­˜é¡è‰²ï¼š{colors}")#è¨»è§£SSS
                # print(f"ğŸŸ« è¾¨è­˜å¤–å‹ï¼š{shape}")#è¨»è§£SSS
                # print(f"ğŸ“Œ æ­£ç¢ºæ–‡å­—ï¼š{expected_text}")#è¨»è§£SSS
                # print(f"ğŸ“Œ æ­£ç¢ºé¡è‰²ï¼š{row.get('é¡è‰²', '')}")#è¨»è§£SSS
                # print(f"ğŸ“Œ æ­£ç¢ºå¤–å‹ï¼š{row.get('å½¢ç‹€', '')}")#è¨»è§£SSS

                # é¡¯ç¤º LCS æœ€çµ‚æ¯”å°åˆ°çš„è—¥å

                # print(f"ğŸ“‹ LCS å°æ‡‰è—¥åï¼ˆvs æ­£ç¢ºè—¥åï¼‰ï¼š")è¨»è§£SSS
                expected_name = raw_name.strip().upper()
                if ocr_match_result:
                    if "front" in ocr_match_result:
                        matched_name = ocr_match_result["front"]["row"]["å­¸å"].strip().upper()
                    #       print(f" - FRONT å°åˆ°ï¼š{matched_name} ï½œæ­£ç¢ºï¼š{expected_name}")è¨»è§£SSS
                    if "back" in ocr_match_result:
                        matched_name = ocr_match_result["back"]["row"]["å­¸å"].strip().upper()
                        # print(f" - BACK  å°åˆ°ï¼š{matched_name} ï½œæ­£ç¢ºï¼š{expected_name}")è¨»è§£SSS

                # === æ–°å¢è¾¨è­˜æˆåŠŸçµ±è¨ˆ ===
                # â¤ æ–‡å­—æˆåŠŸï¼šis_correct ä»£è¡¨å·²æˆåŠŸæ‰¾åˆ°æ­£ç¢ºè—¥å
                is_text_success = is_correct

                # â¤ å¤–å‹æˆåŠŸï¼šæ¯”å°é æ¸¬ shape èˆ‡ row['å½¢ç‹€'] æ˜¯å¦ä¸€è‡´ï¼ˆå¿½ç•¥ç©ºç™½å¤§å°å¯«ï¼‰
                expected_shape = str(row.get("å½¢ç‹€", "")).strip().lower()
                is_shape_success = (shape.strip().lower() == expected_shape) if expected_shape else False

                # print(f"âœ… æ˜¯å¦æ­£ç¢ºè¾¨è­˜ï¼š{'æ˜¯' if is_text_success else 'å¦'}")#è¨»è§£SSS
                # print(f"ğŸ“ˆ æ–‡å­—æˆåŠŸè¾¨è­˜ï¼š{'âœ”ï¸ æˆåŠŸ' if is_text_success else 'âŒ å¤±æ•—'}")#è¨»è§£SSS
                # print(f"ğŸ“ˆ å¤–å‹æˆåŠŸè¾¨è­˜ï¼š{'âœ”ï¸ æˆåŠŸ' if is_shape_success else 'âŒ å¤±æ•—'}")#è¨»è§£SSS
                if is_text_success:
                    text_success_total += 1
                if is_shape_success:
                    shape_success_total += 1

                # print('--------------------------------------------------------------------')#è¨»è§£SSS

            except Exception as e:
                print(f"â— ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # === æœ€å¾Œè¼¸å‡ºçµæœ ===
    if missing_entries:
        print("\nâ—â—â— ä»¥ä¸‹è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œè«‹æª¢æŸ¥ï¼š â—â—â—\n")
        for entry in missing_entries:
            print(f"ç”¨é‡æ’åºï¼š{entry['ç”¨é‡æ’åº']}ï¼Œå­¸åï¼š{entry['å­¸å']}")
        print(f"\nğŸ”´ ç¸½å…± {len(missing_entries)} å€‹è—¥ç‰©è³‡æ–™å¤¾ç¼ºå¤±ã€‚")
    else:
        print("\nâœ… æ‰€æœ‰è³‡æ–™å¤¾çš†æˆåŠŸè®€å–ã€‚")

    print("\nğŸ“Š ç¸½é«”çµ±è¨ˆï¼š")

    print("ğŸ”  æ–‡å­—è¾¨è­˜ï¼š")
    print(f" - è¾¨è­˜çµæœï¼š{text_success_total} å¼µæ­£ç¢º")
    print(f" - æ­£å¼çµæœï¼š{total_images} å¼µï¼ˆç¸½åœ–ç‰‡æ•¸ï¼‰")
    print(f" - è¾¨è­˜æˆåŠŸç‡ï¼š{text_success_total / total_images:.2%}")

    print("\nğŸŸ« å¤–å‹è¾¨è­˜ï¼š")
    print(f" - è¾¨è­˜çµæœï¼š{shape_success_total} å¼µæ­£ç¢º")
    print(f" - æ­£ç¢ºçµæœï¼š{total_images} å¼µï¼ˆç¸½åœ–ç‰‡æ•¸ï¼‰")
    print(f" - è¾¨è­˜æˆåŠŸç‡ï¼š{shape_success_total / total_images:.2%}")

    print("\nğŸ¨ é¡è‰²è¾¨è­˜ï¼š")
    print(f" - è¾¨è­˜çµæœï¼šæœªçµ±è¨ˆï¼ˆå¦‚éœ€çµ±è¨ˆè«‹åŠ ä¸Šçµ±è¨ˆè®Šæ•¸ï¼‰")
    print(f" - æ­£ç¢ºçµæœï¼š{total_images} å¼µï¼ˆç¸½åœ–ç‰‡æ•¸ï¼‰")
    print(f" - è¾¨è­˜æˆåŠŸç‡ï¼šå°šæœªå¯¦ä½œ")

    print("\nğŸ’Š è—¥å“åç¨±æ¯”å°ï¼š")
    print(f" - è¾¨è­˜çµæœï¼š{total_success} å¼µæ¯”å°æˆåŠŸ")
    print(f" - æ­£ç¢ºçµæœï¼š{total_images} å¼µï¼ˆç¸½åœ–ç‰‡æ•¸ï¼‰")
    print(f" - æ•´é«”è¾¨è­˜æˆåŠŸç‡ï¼ˆä»¥æ–‡å­—ç‚ºä¸»ï¼‰ï¼š{total_success / total_images:.2%}")

    print("\nğŸ” Roboflow åµæ¸¬çµ±è¨ˆï¼š")
    print(f" - æˆåŠŸåµæ¸¬åœ–ç‰‡æ•¸ï¼š{roboflow_success} / {roboflow_total}")
    print(f" - åµæ¸¬æˆåŠŸç‡ï¼š{roboflow_success / roboflow_total:.2%}")

    print("ğŸ“¦ å„è—¥å“è¾¨è­˜æƒ…æ³ï¼š")
    for drug, stats in per_drug_stats.items():
        print(f"- {drug}: {stats['success']} / {stats['total']} æˆåŠŸ")


from ultralytics import YOLO

# âœ… å…¨åŸŸè¼‰å…¥æœ¬åœ° YOLO æ¨¡å‹ï¼ˆè«‹æå‰åˆå§‹åŒ–ä¸€æ¬¡ï¼‰
det_model = YOLO("/path/to/best.pt")  # æ›¿æ›æˆä½ çš„ Roboflow åŒ¯å‡º .pt è·¯å¾‘


def process_image(img_path: str):
    """
<<<<<<< HEAD
    å–®å¼µè—¥å“åœ–ç‰‡è¾¨è­˜æµç¨‹ï¼ˆçµ¦ Flask å‘¼å«ï¼‰
    - img_path: åœ–ç‰‡è·¯å¾‘ï¼ˆbase64 decode å¾Œçš„æš«å­˜åœ–ï¼‰
    - return: dictï¼ŒåŒ…å«æ–‡å­—ã€é¡è‰²ã€å½¢ç‹€
    """
    from PIL import Image

    # è®€å–åœ–ç‰‡ï¼ˆè‡ªå‹•åˆ¤æ–·æ˜¯å¦ç‚º HEICï¼‰
    from PIL import Image
    import base64

    # === è®€å–åœ–ç‰‡ ===
    input_img = read_image_safely(img_path)
    if input_img is None:
        return {"error": "ç„¡æ³•è®€å–åœ–ç‰‡"}

    # Roboflow åµæ¸¬
    rgb_pil = Image.fromarray(cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB))
    result = CLIENT.infer(rgb_pil, model_id=MODEL_ID)
    preds = result.get("predictions", [])

    if preds:

        cropped_original, cropped_removed = extract_pill_region(input_img, preds[0])
    else:
        cropped_original, cropped_removed = fallback_rembg_bounding(input_img)

        if cropped_removed is None:
            return {"error": "è—¥å“æ“·å–å¤±æ•—"}

    # === ä½¿ç”¨æœ¬åœ° YOLO æ¨¡å‹é€²è¡Œæ¨è«– ===
    results = det_model(input_img)

    # === è™•ç† YOLO åµæ¸¬çµæœ ===
    preds = results[0].boxes
    if preds and len(preds) > 0:
        # å–æœ€å¤§æ¡†ï¼ˆä¿¡å¿ƒåˆ†æ•¸æœ€é«˜çš„ï¼‰
        boxes = preds.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
        best_idx = preds.conf.argmax().item()
        box = boxes[best_idx]
        x1, y1, x2, y2 = map(int, box)
        cropped_original = input_img[y1:y2, x1:x2]
        cropped_removed = remove(cropped_original)  # ä»ä½¿ç”¨ rembg å»èƒŒ
    else:
        # YOLO åµæ¸¬ä¸åˆ° âœ fallback
        cropped_original, cropped_removed = fallback_rembg_bounding(input_img)
        if cropped_removed is None:
            return {"error": "è—¥å“æ“·å–å¤±æ•—"}

    # === è£åˆ‡åœ–è½‰ Base64 çµ¦å‰ç«¯å±•ç¤º ===
    _, buffer = cv2.imencode(".jpg", cropped_original)
    cropped_base64 = base64.b64encode(buffer).decode("utf-8")
    cropped_base64 = f"data:image/jpeg;base64,{cropped_base64}"

    result["cropped_image"] = cropped_base64
    # å½¢ç‹€è¾¨è­˜
    shape, result = detect_shape_from_image(cropped_removed, cropped_original, expected_shape=None, debug=False)
    # é¡è‰²è¾¨è­˜
    colors = extract_dominant_colors_by_ratio(cropped_removed, visualize=False)

    # å…­å€‹åœ–ç‰‡å¢å¼·ç‰ˆæœ¬
    image_versions = generate_image_versions(cropped_removed)
    # best_texts, best_name, best_score = get_best_ocr_texts(image_versions)
    best_texts, best_name, best_score = get_best_ocr_texts(image_versions, ocr_engine=ocr_engine)
    # === å¤–å‹ã€é¡è‰²åˆ†æ ===
    shape, _ = detect_shape_from_image(cropped_removed, cropped_original, expected_shape=None, debug=False)
    colors = extract_dominant_colors_by_ratio(cropped_removed, visualize=False)

    # === å¤šç‰ˆæœ¬ OCR è¾¨è­˜ ===
    image_versions = generate_image_versions(cropped_removed)
    best_texts, best_name, best_score = get_best_ocr_texts(image_versions, ocr_engine=ocr_engine)

    print("æ–‡å­—è¾¨è­˜ï¼š" + str(best_texts if best_texts else ["None"]))
    print("æœ€ä½³ç‰ˆæœ¬ï¼š" + str(best_name))
    print("ä¿¡å¿ƒåˆ†æ•¸ï¼š" + str(round(best_score, 3)))
    print("é¡è‰²ï¼š" + str(colors))
    print("å¤–å‹ï¼š" + str(shape))

    return {
        "æ–‡å­—è¾¨è­˜": best_texts if best_texts else ["None"],
        "æœ€ä½³ç‰ˆæœ¬": best_name,
        "ä¿¡å¿ƒåˆ†æ•¸": round(best_score, 3),
        "é¡è‰²": colors,
        "å¤–å‹": shape,
        "cropped_image": cropped_base64   # <=== é€™æ˜¯è£åˆ‡åœ–
    }
